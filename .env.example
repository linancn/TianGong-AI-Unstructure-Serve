MINERU_MODEL_SOURCE=modelscope
MINERU_OFFICE_CONVERT_TIMEOUT_SECONDS=600

# MinerU parsing defaults (see README for options)
# backend options: pipeline, vlm-transformers, vlm-vllm-engine, vlm-lmdeploy-engine, vlm-http-client, vlm-mlx-engine
MINERU_DEFAULT_BACKEND=vlm-http-client
MINERU_DEFAULT_LANG=ch
MINERU_DEFAULT_METHOD=auto
# Comma-separated or JSON list of VLM endpoints; falls back to http://127.0.0.1:30000
MINERU_VLLM_SERVER_URLS=http://127.0.0.1:30000
# Optional auth for http-client backend; prefer MINERU_VLLM_AUTH_HEADER if you need a custom scheme
# MINERU_VLLM_API_KEY=
# MINERU_VLLM_AUTH_HEADER=Bearer <token>

# FastAPI authentication toggle (override secrets.toml)
FASTAPI_AUTH=true

# Scheduler / MinerU timeouts (seconds)
MINERU_TASK_HARD_TIMEOUT_SECONDS=1800
MINERU_DEFAULT_HARD_TIMEOUT_SECONDS=1800
MINERU_IMAGES_HARD_TIMEOUT_SECONDS=1800
MINERU_SCI_HARD_TIMEOUT_SECONDS=600
MINERU_SCI_TIMEOUT_SECONDS=110

# GPU scheduler device list
GPU_IDS=0,1,2

WEAVIATE_HTTP_HOST=localhost
WEAVIATE_HTTP_PORT=8080
WEAVIATE_GRPC_HOST=localhost
WEAVIATE_GRPC_PORT=50051
# WEAVIATE_API_KEY=

# Vision routing defaults
VISION_PROVIDER=gemini
VISION_MODEL=gemini-2.5-flash

VISION_PROVIDER_CHOICES=openai,gemini,vllm

VISION_MODELS_OPENAI=gpt-5-mini
VISION_DEFAULT_MODEL_OPENAI=gpt-5-mini

VISION_MODELS_GEMINI=gemini-2.5-flash
VISION_DEFAULT_MODEL_GEMINI=gemini-2.5-flash

VISION_MODELS_VLLM=Qwen/Qwen3-VL-30B-A3B-Instruct-FP8
VISION_DEFAULT_MODEL_VLLM=Qwen/Qwen3-VL-30B-A3B-Instruct-FP8

# Default context window for vision models is 2, can be overridden per request
VISION_CONTEXT_WINDOW=2

# vLLM endpoint config (API key lives in secrets.toml)
VLLM_BASE_URL=http://localhost:8000/v1
# VLLM_API_KEY is optional; leave blank for keyless local deployments

# Path to pandoc binary used for Markdown conversion
PANDOC_PATH=pandoc
